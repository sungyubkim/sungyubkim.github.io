<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unified Sequence Parallelism | Sung-Yub Kim </title> <meta name="author" content="Sung-Yub Kim"> <meta name="description" content="Unified Sequence Parallelism (USP) combines Ulysses and Ring Attention for scalable long-sequence training up to 208K tokens."> <meta name="keywords" content="machine-learning, deep-learning, llm, foundation-models, research"> <meta property="og:site_name" content="Sung-Yub Kim"> <meta property="og:type" content="article"> <meta property="og:title" content="Sung-Yub Kim | Unified Sequence Parallelism"> <meta property="og:url" content="https://sungyubkim.github.io/blog/usp/"> <meta property="og:description" content="Unified Sequence Parallelism (USP) combines Ulysses and Ring Attention for scalable long-sequence training up to 208K tokens."> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Unified Sequence Parallelism"> <meta name="twitter:description" content="Unified Sequence Parallelism (USP) combines Ulysses and Ring Attention for scalable long-sequence training up to 208K tokens."> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Sung-Yub Kim"
        },
        "url": "https://sungyubkim.github.io/blog/usp/",
        "@type": "BlogPosting",
        "description": "Unified Sequence Parallelism (USP) combines Ulysses and Ring Attention for scalable long-sequence training up to 208K tokens.",
        "headline": "Unified Sequence Parallelism",
        
        "sameAs": ["https://github.com/sungyubkim","https://scholar.google.com/citations?user=m2rhgrkAAAAJ","https://www.linkedin.com/in/sung-yub-kim-0a82a1264","https://twitter.com/SungyubK"],
        
        "name": "Sung-Yub Kim",
        "@context": "https://schema.org"
    }
  </script> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?v=6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%A0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sungyubkim.github.io/blog/usp/"> <script src="/assets/js/theme.js?v=48c9b5bd7f2e0605e39e579400e22553"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Sung-Yub</span> Kim </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unified Sequence Parallelism</h1> <p class="post-meta"> Created on June 02, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/sequence-parallelism"> <i class="fa-solid fa-hashtag fa-sm"></i> sequence-parallelism</a>   <a href="/blog/tag/distributed-training"> <i class="fa-solid fa-hashtag fa-sm"></i> distributed-training</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="tldr">TL;DR</h1> <blockquote> <p><strong>이 논문은 무엇에 관한 것인가?</strong> 이 논문은 매우 긴 입력 시퀀스(책 전체를 읽거나 몇 시간의 비디오를 처리하는 것과 같은)를 가진 대형 AI 모델을 훈련시키는 데 있어서의 중요한 문제를 해결합니다. 저자들은 “Ulysses”와 “Ring Attention”이라는 두 가지 기존 기술을 결합한 USP(Unified Sequence Parallelism)를 만들어 최대 208,000 토큰 길이의 시퀀스(약 400페이지 분량의 텍스트)로 AI 모델을 훈련할 수 있게 했습니다.</p> <p><strong>주요 기여:</strong></p> <ol> <li> <strong>통합 방법론</strong>: 두 가지 경쟁하는 접근 방식(Ulysses vs Ring) 중 하나를 선택하는 대신, USP는 둘을 지능적으로 결합하여 각각의 장점을 모두 얻습니다</li> </ol> </blockquote> <ul> <li>Paper Link: <a href="https://arxiv.org/pdf/2405.07719" rel="external nofollow noopener" target="_blank">https://arxiv.org/pdf/2405.07719</a> </li> </ul> <hr> <h1 id="related-papers">Related Papers</h1> <p><strong>통합된 방법론의 기반:</strong></p> <ul> <li> <a href="/blog/deepspeed_ulysses/">DeepSpeed Ulysses</a> - USP에서 통합된 Ulysses 방법</li> <li> <a href="/blog/blockwise_ringattention/">Blockwise RingAttention</a> - USP에서 통합된 Ring 방법</li> <li> <a href="/blog/ring-self-attention/">Ring Self-Attention</a> - 시퀀스 병렬화의 체계적 분석</li> </ul> <p><strong>하이브리드 병렬화:</strong></p> <ul> <li> <a href="https://arxiv.org/pdf/2406.18485" rel="external nofollow noopener" target="_blank">LoongTrain</a> - 2D 어텐션을 활용한 하이브리드 접근법</li> <li> <a href="/blog/tp/">Tensor Parallelism</a> - 텐서 병렬화와의 결합</li> <li> <a href="/blog/pp/">GPipe</a> - 파이프라인 병렬화와의 통합</li> </ul> <p><strong>긴 시퀀스 처리:</strong></p> <ul> <li> <a href="https://arxiv.org/pdf/2310.03294" rel="external nofollow noopener" target="_blank">DISTFLASHATTN</a> - 분산 어텐션 계산</li> <li> <a href="https://arxiv.org/pdf/2311.09431" rel="external nofollow noopener" target="_blank">Striped Attention</a> - 효율적인 시퀀스 분배</li> <li> <a href="https://arxiv.org/pdf/2411.01783" rel="external nofollow noopener" target="_blank">Context Parallelism for Scalable Million-Token Inference</a> - 추론 시 컨텍스트 병렬화</li> </ul> <p><strong>시스템 최적화:</strong></p> <ul> <li> <a href="/blog/sp/">Reducing Activation Recomputation in Large Transformer Models</a> - 메모리 효율적인 훈련</li> <li> <a href="https://arxiv.org/pdf/2211.05102" rel="external nofollow noopener" target="_blank">Efficiently Scaling Transformer Inference</a> - 효율적 추론 시스템</li> </ul> <hr> <ol> <li> <strong>하드웨어 적응성</strong>: 사용 가능한 네트워크 하드웨어(빠른 NVLink vs 느린 PCIe 연결)에 따라 자동으로 성능을 최적화합니다</li> <li> <strong>실용적 가이드라인</strong>: 실제 시스템에서 언제, 어떻게 다른 병렬화 전략을 사용할지에 대한 명확한 규칙을 제공합니다</li> <li> <strong>획기적인 결과</strong>: 208K 토큰 시퀀스 훈련에서 47% 계산 효율성 달성 - 새로운 최고 수준</li> </ol> <p><strong>왜 이것이 중요한가:</strong> 이 연구 이전에는 매우 긴 시퀀스로 AI 모델을 훈련하는 것이 메모리 제한으로 인해 불가능하거나 극도로 비효율적이었습니다. USP는 훨씬 더 긴 맥락을 이해할 수 있는 모델을 훈련하는 것을 실용적으로 만들어, 전체 문서 분석, 긴 대화, 확장된 비디오 시퀀스와 같은 애플리케이션을 가능하게 합니다.</p> <hr> <h1 id="takeaways">Takeaways</h1> <h2 id="핵심-문제-긴-시퀀스가-왜-어려운가">핵심 문제: 긴 시퀀스가 왜 어려운가</h2> <h3 id="메모리-벽-도전">메모리 벽 도전</h3> <p><strong>동기</strong>: 현대 AI 애플리케이션은 점점 더 긴 시퀀스를 처리해야 합니다. Claude는 100K 토큰을 처리할 수 있고, GPT-4는 128K를, Gemini 1.5 Pro는 1천만 토큰을 주장합니다. 하지만 근본적인 문제가 있습니다: 트랜스포머의 어텐션 메커니즘은 이차 메모리 복잡도를 가집니다.</p> <p><strong>구체적인 예시</strong>:</p> <ul> <li>1,000 토큰 시퀀스: 어텐션에 약 1M 메모리 단위 필요</li> <li>10,000 토큰 시퀀스: 약 100M 메모리 단위 필요</li> <li>100,000 토큰 시퀀스: 약 10B 메모리 단위 필요</li> </ul> <p>이러한 이차 증가는 긴 시퀀스를 처리할 때 단일 GPU가 빠르게 메모리 부족 상태가 된다는 의미입니다.</p> <p><strong>전통적인 해결책과 그 한계들</strong>:</p> <p>논문은 기존 해결책들이 치명적인 결함을 가지고 있다고 식별합니다:</p> <ol> <li> <p><strong>데이터 병렬화 (DP)</strong>: 장치 간 데이터를 분할하지만 큰 배치 크기가 필요</p> <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code> <span class="c1"># 문제: 긴 시퀀스에 대해 충분한 배치 크기가 없음
</span> <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="n">num_devices</span><span class="p">:</span>
     <span class="k">raise</span> <span class="nc">Error</span><span class="p">(</span><span class="sh">"</span><span class="s">데이터 병렬화를 효과적으로 사용할 수 없음</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div> </div> </li> <li> <p><strong>텐서 병렬화 (TP)</strong>: 모델 가중치를 분할하지만 어텐션 헤드 수에 의해 제한됨</p> <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code> <span class="c1"># 문제: 제한된 확장성
</span> <span class="n">max_tp_degree</span> <span class="o">=</span> <span class="n">num_attention_heads</span>  <span class="c1"># 종종 32-64개만
</span> <span class="k">if</span> <span class="n">required_devices</span> <span class="o">&gt;</span> <span class="n">max_tp_degree</span><span class="p">:</span>
     <span class="k">raise</span> <span class="nc">Error</span><span class="p">(</span><span class="sh">"</span><span class="s">헤드 수를 넘어서 확장할 수 없음</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div> </div> </li> <li> <p><strong>기존 시퀀스 병렬화</strong>: 주요 제한사항을 가진 두 가지 경쟁 접근법:</p> <ul> <li> <strong>DeepSpeed-Ulysses</strong>: 빠르지만 어텐션 헤드 수에 의해 제한됨</li> <li> <strong>Ring-Attention</strong>: 확장 가능하지만 계산적으로 비효율적</li> </ul> </li> </ol> <h2 id="usp-해결책-두-세계의-장점">USP 해결책: 두 세계의 장점</h2> <h3 id="핵심-통찰-왜-둘-다-안-되나">핵심 통찰: 왜 둘 다 안 되나?</h3> <p>논문의 핵심 통찰은 Ulysses와 Ring 어텐션이 상호 배타적이지 않다는 것입니다 - 그들은 함께 작동할 수 있습니다. 이것은 빠른 자동차와 연료 효율적인 자동차 중 하나를 선택할 필요가 없다는 것을 깨닫는 것과 같습니다; 빠르면서 동시에 효율적인 하이브리드를 설계할 수 있습니다.</p> <h3 id="usp-방법-설명">USP 방법 설명</h3> <p><strong>1단계: 프로세스 그룹 조직</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">setup_usp_groups</span><span class="p">(</span><span class="n">total_devices</span><span class="p">,</span> <span class="n">ulysses_degree</span><span class="p">,</span> <span class="n">ring_degree</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    장치들을 2D 메시로 조직:
    - 행: Ulysses 그룹 (고대역폭 AllToAll)
    - 열: Ring 그룹 (P2P 통신)
    </span><span class="sh">"""</span>
    <span class="k">assert</span> <span class="n">total_devices</span> <span class="o">==</span> <span class="n">ulysses_degree</span> <span class="o">*</span> <span class="n">ring_degree</span>
    
    <span class="c1"># 예시: 8개 장치 = 2×4 메시
</span>    <span class="c1"># 장치 배치:
</span>    <span class="c1"># [0, 1, 2, 3]  &lt;- Ring 그룹 0
</span>    <span class="c1"># [4, 5, 6, 7]  &lt;- Ring 그룹 1
</span>    <span class="c1"># |  |  |  |
</span>    <span class="c1"># Ulysses 그룹 (열)
</span>    
    <span class="k">for</span> <span class="n">ring_id</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">ring_degree</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">ulysses_id</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">ulysses_degree</span><span class="p">):</span>
            <span class="n">device_id</span> <span class="o">=</span> <span class="n">ring_id</span> <span class="o">*</span> <span class="n">ulysses_degree</span> <span class="o">+</span> <span class="n">ulysses_id</span>
            <span class="nf">assign_device</span><span class="p">(</span><span class="n">device_id</span><span class="p">,</span> <span class="n">ulysses_group</span><span class="o">=</span><span class="n">ulysses_id</span><span class="p">,</span> <span class="n">ring_group</span><span class="o">=</span><span class="n">ring_id</span><span class="p">)</span>
</code></pre></div></div> <p><strong>2단계: 인과 어텐션을 위한 로드 밸런싱</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">balance_causal_workload</span><span class="p">(</span><span class="n">sequence_tokens</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    문제: 인과 어텐션에서 초기 토큰들은 더 적은 토큰에 어텐션함
    - 토큰 0은 [0]에 어텐션 (1개 연산)
    - 토큰 1은 [0,1]에 어텐션 (2개 연산) 
    - 토큰 15는 [0,1,2...15]에 어텐션 (16개 연산)
    
    해결책: 각 장치가 동일한 작업을 갖도록 토큰을 재분배
    </span><span class="sh">"""</span>
    <span class="c1"># 원래 할당 (불균형):
</span>    <span class="c1"># 장치 0: 토큰 [0,1,2,3] → 1+2+3+4 = 10 연산
</span>    <span class="c1"># 장치 3: 토큰 [12,13,14,15] → 13+14+15+16 = 58 연산
</span>    
    <span class="c1"># 로드 밸런싱된 할당:
</span>    <span class="c1"># 장치 0: 토큰 [0,1,14,15] → 1+2+15+16 = 34 연산  
</span>    <span class="c1"># 장치 3: 토큰 [6,7,8,9] → 7+8+9+10 = 34 연산
</span>    
    <span class="n">reordered_tokens</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">chunk_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">sequence_tokens</span><span class="p">)</span> <span class="o">//</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">num_devices</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">device</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_devices</span><span class="p">):</span>
        <span class="c1"># 각 장치는 시작과 끝에서 하나씩 청크를 받음
</span>        <span class="n">start_chunk</span> <span class="o">=</span> <span class="n">sequence_tokens</span><span class="p">[</span><span class="n">device</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">:(</span><span class="n">device</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">]</span>
        <span class="n">end_chunk</span> <span class="o">=</span> <span class="n">sequence_tokens</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">device</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">:</span><span class="o">-</span><span class="n">device</span> <span class="o">*</span> <span class="n">chunk_size</span><span class="p">]</span>
        <span class="n">reordered_tokens</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">start_chunk</span> <span class="o">+</span> <span class="n">end_chunk</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">reordered_tokens</span>
</code></pre></div></div> <p><strong>3단계: 통합 어텐션 알고리즘</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">usp_attention</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">ulysses_group</span><span class="p">,</span> <span class="n">ring_group</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    두 접근법을 결합한 완전한 USP 어텐션 메커니즘
    
    입력: 시퀀스 차원으로 분할된 Q,K,V 텐서
    출력: 동일한 분할을 가진 어텐션 출력
    </span><span class="sh">"""</span>
    
    <span class="c1"># 단계 1: Ulysses AllToAll (시퀀스 → 헤드)
</span>    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Ulysses 이전: Q 형태 = </span><span class="si">{</span><span class="n">Q</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># [batch, seq/N, heads, dim]
</span>    
    <span class="n">Q_heads</span> <span class="o">=</span> <span class="nf">all_to_all_4d</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">scatter_seq</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">gather_heads</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">ulysses_group</span><span class="p">)</span>
    <span class="n">K_heads</span> <span class="o">=</span> <span class="nf">all_to_all_4d</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">scatter_seq</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">gather_heads</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">ulysses_group</span><span class="p">)</span> 
    <span class="n">V_heads</span> <span class="o">=</span> <span class="nf">all_to_all_4d</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">scatter_seq</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">gather_heads</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">ulysses_group</span><span class="p">)</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Ulysses 이후: Q 형태 = </span><span class="si">{</span><span class="n">Q_heads</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># [batch, seq, heads/M, dim]
</span>    
    <span class="c1"># 단계 2: P2P 통신을 가진 Ring 어텐션
</span>    <span class="n">O_ring</span> <span class="o">=</span> <span class="nf">ring_attention_with_p2p</span><span class="p">(</span><span class="n">Q_heads</span><span class="p">,</span> <span class="n">K_heads</span><span class="p">,</span> <span class="n">V_heads</span><span class="p">,</span> <span class="n">ring_group</span><span class="p">)</span>
    
    <span class="c1"># 단계 3: 역 Ulysses AllToAll (헤드 → 시퀀스)  
</span>    <span class="n">O_final</span> <span class="o">=</span> <span class="nf">all_to_all_4d</span><span class="p">(</span><span class="n">O_ring</span><span class="p">,</span> <span class="n">scatter_heads</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">gather_seq</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">ulysses_group</span><span class="p">)</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">최종 출력: O 형태 = </span><span class="si">{</span><span class="n">O_final</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># [batch, seq/N, heads, dim]
</span>    
    <span class="k">return</span> <span class="n">O_final</span>

<span class="k">def</span> <span class="nf">ring_attention_with_p2p</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">ring_group</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">P2P를 통해 장치 간에 K,V 블록을 전달하는 Ring 어텐션</span><span class="sh">"""</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
    
    <span class="c1"># 각 장치는 자신의 K,V 블록으로 시작
</span>    <span class="n">my_K</span><span class="p">,</span> <span class="n">my_V</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="nf">clone</span><span class="p">(),</span> <span class="n">V</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">ring_group</span><span class="p">.</span><span class="nf">size</span><span class="p">()):</span>
        <span class="c1"># 현재 K,V 블록으로 어텐션 계산
</span>        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">my_K</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">attention_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">partial_output</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">my_V</span><span class="p">)</span>
        
        <span class="c1"># 결과 누적
</span>        <span class="n">output</span> <span class="o">+=</span> <span class="n">partial_output</span>
        
        <span class="c1"># 링의 다음 장치로 K,V 전달 (마지막 단계 제외)
</span>        <span class="k">if</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="n">ring_group</span><span class="p">.</span><span class="nf">size</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">next_device</span> <span class="o">=</span> <span class="p">(</span><span class="n">ring_group</span><span class="p">.</span><span class="nf">rank</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">ring_group</span><span class="p">.</span><span class="nf">size</span><span class="p">()</span>
            <span class="n">prev_device</span> <span class="o">=</span> <span class="p">(</span><span class="n">ring_group</span><span class="p">.</span><span class="nf">rank</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">ring_group</span><span class="p">.</span><span class="nf">size</span><span class="p">()</span>
            
            <span class="c1"># 동시 송수신
</span>            <span class="n">ring_group</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="n">my_K</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="n">next_device</span><span class="p">)</span>
            <span class="n">ring_group</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="n">my_V</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="n">next_device</span><span class="p">)</span> 
            <span class="n">my_K</span> <span class="o">=</span> <span class="n">ring_group</span><span class="p">.</span><span class="nf">recv</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">prev_device</span><span class="p">)</span>
            <span class="n">my_V</span> <span class="o">=</span> <span class="n">ring_group</span><span class="p">.</span><span class="nf">recv</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">prev_device</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output</span>
</code></pre></div></div> <p><strong>구체적인 예시</strong>: 4개 장치, 64 토큰, 16 헤드로 USP를 추적해보겠습니다:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 초기 상태: 각 장치가 16 토큰, 모든 16 헤드를 가짐
</span><span class="n">장치_0</span><span class="p">:</span> <span class="n">Q</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span> <span class="c1"># 토큰 0-15
</span><span class="n">장치_1</span><span class="p">:</span> <span class="n">Q</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span> <span class="c1"># 토큰 16-31  
</span><span class="n">장치_2</span><span class="p">:</span> <span class="n">Q</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span> <span class="c1"># 토큰 32-47
</span><span class="n">장치_3</span><span class="p">:</span> <span class="n">Q</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span> <span class="c1"># 토큰 48-63
</span>
<span class="c1"># Ulysses AllToAll 이후 (ulysses_degree=2): 시퀀스 분산, 헤드 분할
</span><span class="n">장치_0</span><span class="p">:</span> <span class="n">Q</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>  <span class="c1"># 토큰 0-31, 헤드 0-7
</span><span class="n">장치_1</span><span class="p">:</span> <span class="n">Q</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>  <span class="c1"># 토큰 0-31, 헤드 8-15
</span><span class="n">장치_2</span><span class="p">:</span> <span class="n">Q</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>  <span class="c1"># 토큰 32-63, 헤드 0-7  
</span><span class="n">장치_3</span><span class="p">:</span> <span class="n">Q</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>  <span class="c1"># 토큰 32-63, 헤드 8-15
</span>
<span class="c1"># Ring 어텐션 (ring_degree=2): 각 쌍 내에서 P2P 통신
# 장치 0&amp;2가 헤드 0-7에 대한 링 형성
# 장치 1&amp;3이 헤드 8-15에 대한 링 형성
</span>
<span class="c1"># 역 Ulysses 이후: 시퀀스 분할로 복귀
</span><span class="n">장치_0</span><span class="p">:</span> <span class="n">O</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span> <span class="c1"># 토큰 0-15에 대한 최종 출력
</span><span class="n">장치_1</span><span class="p">:</span> <span class="n">O</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span> <span class="c1"># 토큰 16-31에 대한 최종 출력
</span><span class="n">장치_2</span><span class="p">:</span> <span class="n">O</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span> <span class="c1"># 토큰 32-47에 대한 최종 출력
</span><span class="n">장치_3</span><span class="p">:</span> <span class="n">O</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span> <span class="c1"># 토큰 48-63에 대한 최종 출력
</span></code></pre></div></div> <h3 id="중요한-가정과-성공-조건">중요한 가정과 성공 조건</h3> <p>논문은 USP가 효과적으로 작동하기 위해 충족되어야 하는 몇 가지 중요한 가정을 드러냅니다:</p> <p><strong>수학적 요구사항:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">validate_usp_configuration</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">ulysses_degree</span><span class="p">,</span> <span class="n">ring_degree</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">만족되어야 하는 중요한 조건들</span><span class="sh">"""</span>
    
    <span class="c1"># 조건 1: 헤드 분할 가능성
</span>    <span class="k">assert</span> <span class="n">num_heads</span> <span class="o">%</span> <span class="n">ulysses_degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> \
        <span class="sa">f</span><span class="sh">"</span><span class="s">헤드 </span><span class="si">{</span><span class="n">num_heads</span><span class="si">}</span><span class="s">는 Ulysses 차수 </span><span class="si">{</span><span class="n">ulysses_degree</span><span class="si">}</span><span class="s">로 균등분할되어야 함</span><span class="sh">"</span>
    
    <span class="c1"># 조건 2: 시퀀스 분할 가능성  
</span>    <span class="n">total_sp_degree</span> <span class="o">=</span> <span class="n">ulysses_degree</span> <span class="o">*</span> <span class="n">ring_degree</span>
    <span class="k">assert</span> <span class="n">seq_len</span> <span class="o">%</span> <span class="n">total_sp_degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> \
        <span class="sa">f</span><span class="sh">"</span><span class="s">시퀀스 길이 </span><span class="si">{</span><span class="n">seq_len</span><span class="si">}</span><span class="s">는 총 SP 차수 </span><span class="si">{</span><span class="n">total_sp_degree</span><span class="si">}</span><span class="s">로 분할되어야 함</span><span class="sh">"</span>
    
    <span class="c1"># 조건 3: 장치당 메모리 제약
</span>    <span class="n">memory_per_device</span> <span class="o">=</span> <span class="nf">estimate_memory</span><span class="p">(</span><span class="n">seq_len</span> <span class="o">//</span> <span class="n">ring_degree</span><span class="p">,</span> <span class="n">num_heads</span> <span class="o">//</span> <span class="n">ulysses_degree</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">memory_per_device</span> <span class="o">&lt;</span> <span class="n">available_gpu_memory</span><span class="p">,</span> <span class="sh">"</span><span class="s">GPU 메모리 부족</span><span class="sh">"</span>
    
    <span class="c1"># 조건 4: 통신 대역폭 요구사항
</span>    <span class="n">ulysses_bandwidth_needed</span> <span class="o">=</span> <span class="nf">estimate_alltoall_bandwidth</span><span class="p">(</span><span class="n">ulysses_degree</span><span class="p">)</span>
    <span class="n">ring_bandwidth_needed</span> <span class="o">=</span> <span class="nf">estimate_p2p_bandwidth</span><span class="p">(</span><span class="n">ring_degree</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="bp">True</span>
</code></pre></div></div> <p><strong>하드웨어 토폴로지 요구사항:</strong></p> <ul> <li> <strong>Ulysses를 위한 높은 대역폭</strong>: AllToAll 연산은 NVLink 수준의 연결(400GB/s+)이 필요</li> <li> <strong>Ring을 위한 낮은 대역폭도 가능</strong>: P2P는 PCIe나 이더넷 연결에서도 작동 가능</li> <li> <strong>네트워크 토폴로지 인식</strong>: USP는 Ulysses 그룹이 고대역폭 도메인에 매핑될 때 최고 성능을 발휘</li> </ul> <p><strong>내 분석</strong>: 논문의 강점은 이러한 가정들을 명시적으로 만드는 것입니다. 이전 연구들은 종종 이상적인 네트워크 조건을 가정했지만, USP는 실제 하드웨어 제한을 인정하고 그에 따라 적응합니다.</p> <h2 id="실험-결과-숫자들이-실제로-의미하는-것">실험 결과: 숫자들이 실제로 의미하는 것</h2> <h3 id="주요-성능-결과">주요 성능 결과</h3> <table> <thead> <tr> <th><strong>구성</strong></th> <th><strong>하드웨어</strong></th> <th><strong>시퀀스 길이</strong></th> <th><strong>MFU</strong></th> <th><strong>내 해석</strong></th> </tr> </thead> <tbody> <tr> <td><strong>LLAMA3-8B</strong></td> <td>2×8xA800</td> <td>208K 토큰</td> <td><strong>47%</strong></td> <td> <strong>획기적</strong>: 극한 시퀀스 길이에서 생산 수준 효율성을 달성한 첫 번째 사례</td> </tr> <tr> <td><strong>LLAMA3-8B</strong></td> <td>2×8xA800</td> <td>120K 토큰</td> <td><strong>49%</strong></td> <td> <strong>최적점</strong>: 메모리와 계산의 최적 균형</td> </tr> <tr> <td><strong>LLAMA2-7B</strong></td> <td>1×8xA800</td> <td>64K 토큰</td> <td><strong>50%</strong></td> <td> <strong>확장성 검증</strong>: 단일 노드 성능이 기준선 확립</td> </tr> </tbody> </table> <p><strong>이러한 결과에 대한 내 생각:</strong></p> <ul> <li> <strong>208K에서 47% MFU는 놀랍다</strong> - 대부분의 시스템이 이런 규모에서 &gt;30% 효율성을 유지하는 데 어려움을 겪음</li> <li> <strong>49%에서 47%로의 약간의 효율성 감소</strong>는 USP가 알고리즘적 병목보다는 하드웨어 한계에 접근하고 있음을 시사</li> <li> <strong>일관된 47-50% 범위</strong>는 USP가 안정적인 성능 특성을 가지고 있음을 나타냄</li> </ul> <h3 id="절제-연구-usp-vs-개별-방법들">절제 연구: USP vs 개별 방법들</h3> <table> <thead> <tr> <th><strong>하드웨어 유형</strong></th> <th><strong>시퀀스</strong></th> <th><strong>SP-Ulysses</strong></th> <th><strong>SP-Ring</strong></th> <th><strong>USP-통합</strong></th> <th><strong>승자</strong></th> <th><strong>왜?</strong></th> </tr> </thead> <tbody> <tr> <td><strong>8xL20 PCIe</strong></td> <td>32K</td> <td>28.6 iter/s</td> <td><strong>62.8 iter/s</strong></td> <td><strong>62.8 iter/s</strong></td> <td>Ring/USP</td> <td>낮은 대역폭이 P2P를 선호</td> </tr> <tr> <td><strong>8xL20 PCIe</strong></td> <td>128K</td> <td>3.2 iter/s</td> <td><strong>5.5 iter/s</strong></td> <td><strong>5.5 iter/s</strong></td> <td>Ring/USP</td> <td>+71% 개선</td> </tr> <tr> <td><strong>8xA100 NVLink</strong></td> <td>32K</td> <td><strong>136.4 iter/s</strong></td> <td>133.0 iter/s</td> <td><strong>136.4 iter/s</strong></td> <td>Ulysses/USP</td> <td>높은 대역폭이 AllToAll 가능하게 함</td> </tr> <tr> <td><strong>8xA100 NVLink</strong></td> <td>128K</td> <td><strong>2.8 iter/s</strong></td> <td>2.9 iter/s</td> <td><strong>2.8 iter/s</strong></td> <td>Ulysses/USP</td> <td>미미한 차이</td> </tr> </tbody> </table> <p><strong>내 분석의 핵심 통찰:</strong></p> <ol> <li> <strong>하드웨어-알고리즘 매칭</strong>: 최고의 접근법은 전적으로 네트워크 토폴로지에 달려있음 - 범용 승자는 없음</li> <li> <strong>PCIe 시스템은 Ring을 강하게 선호</strong>: 71% 개선은 P2P 통신이 낮은 대역폭에 훨씬 더 적합함을 보여줌</li> <li> <strong>NVLink 시스템은 Ulysses를 약간 선호</strong>: AllToAll 연산이 높은 대역폭에서 빛나지만, 장점이 예상보다 작음</li> <li> <strong>USP의 가치</strong>: 항상 최고의 개별 방법과 일치하여, 수동 알고리즘 선택의 필요성을 제거</li> </ol> <h3 id="로드-밸런싱-영향-분석">로드 밸런싱 영향 분석</h3> <table> <thead> <tr> <th><strong>방법</strong></th> <th><strong>시퀀스 길이</strong></th> <th><strong>기준선</strong></th> <th><strong>로드 밸런싱</strong></th> <th><strong>개선</strong></th> <th><strong>내 분석</strong></th> </tr> </thead> <tbody> <tr> <td><strong>Ring 어텐션</strong></td> <td>32K</td> <td>28.6 iter/s</td> <td><strong>32.8 iter/s</strong></td> <td><strong>+14.8%</strong></td> <td>중간 길이에서 적당한 이득</td> </tr> <tr> <td><strong>Ring 어텐션</strong></td> <td>128K</td> <td>3.2 iter/s</td> <td><strong>4.2 iter/s</strong></td> <td><strong>+31.6%</strong></td> <td><strong>긴 시퀀스에서 엄청난 이득</strong></td> </tr> </tbody> </table> <p><strong>왜 이것이 중요한가 (내 해석):</strong></p> <ul> <li> <strong>개선이 시퀀스 길이와 함께 증가</strong> - 이는 로드 밸런싱이 USP가 목표로 하는 가장 긴 시퀀스에서 중요해진다는 것을 시사</li> <li> <strong>31.6% 개선은 엄청나다</strong> - 이 단일 최적화가 많은 알고리즘적 발전보다 더 많은 속도 향상을 제공</li> <li> <strong>핵심 기여를 검증</strong> - 로드 밸런싱은 단순히 좋은 기능이 아니라 USP 성공에 필수적</li> </ul> <h3 id="메모리-vs-통신-트레이드오프">메모리 vs 통신 트레이드오프</h3> <table> <thead> <tr> <th><strong>방법</strong></th> <th><strong>통신 볼륨</strong></th> <th><strong>메모리 효율성</strong></th> <th><strong>최적 사용 사례</strong></th> <th><strong>내 평가</strong></th> </tr> </thead> <tbody> <tr> <td><strong>데이터 병렬</strong></td> <td>높음 (AllReduce 그래디언트)</td> <td>우수 (A/N)</td> <td><strong>짧은 시퀀스, 큰 배치</strong></td> <td>적용 가능할 때 여전히 황금 표준</td> </tr> <tr> <td><strong>SP-Ulysses</strong></td> <td>매우 높음 (8×AllToAll)</td> <td>좋음 (A/N)</td> <td><strong>높은 대역폭, 헤드가 많은 모델</strong></td> <td>통신 병목이 확장을 제한</td> </tr> <tr> <td><strong>SP-Ring</strong></td> <td>중간 (4×P2P)</td> <td>좋음 (A/N)</td> <td><strong>낮은 대역폭, 메모리 제약</strong></td> <td>대부분의 시나리오에서 예상보다 좋음</td> </tr> <tr> <td><strong>USP-통합</strong></td> <td><strong>적응형</strong></td> <td>좋음 (A/N)</td> <td><strong>모든 하드웨어 토폴로지</strong></td> <td><strong>최고의 범용 솔루션</strong></td> </tr> <tr> <td><strong>TP-sp</strong></td> <td>높음 (10×AllGather)</td> <td> <strong>최고</strong> (αA, α&lt;1)</td> <td><strong>메모리 중요 시나리오</strong></td> <td>극한 메모리 제약에서 여전히 필요</td> </tr> </tbody> </table> <p><strong>내 전략적 분석:</strong></p> <ol> <li> <strong>USP가 모든 것을 대체하지는 않음</strong> - TP-sp는 여전히 극한 규모에서 중요한 메모리 장점을 가짐</li> <li> <strong>통신 적응성이 USP의 킬러 기능</strong> - 다른 방법은 하드웨어에 맞게 자동 최적화하지 않음</li> <li> <strong>메모리 효율성은 “충분히 좋다”</strong> - USP는 주요 요구사항인 중요한 A/N 확장을 달성</li> </ol> <h3 id="수렴-검증-숨겨진-영웅">수렴 검증: 숨겨진 영웅</h3> <table> <thead> <tr> <th><strong>방법</strong></th> <th><strong>훈련 손실</strong></th> <th><strong>수렴 속도</strong></th> <th><strong>수치적 안정성</strong></th> </tr> </thead> <tbody> <tr> <td><strong>데이터 병렬</strong></td> <td>2.45 (기준선)</td> <td>정상</td> <td>안정적</td> </tr> <tr> <td><strong>USP</strong></td> <td><strong>2.45 (동일)</strong></td> <td><strong>동일</strong></td> <td><strong>안정적</strong></td> </tr> </tbody> </table> <p><strong>이 결과가 중요한 이유 (내 관점):</strong></p> <ul> <li> <strong>완벽한 수렴 매칭</strong>은 USP가 훈련 아티팩트를 도입하지 않음을 증명</li> <li> <strong>동일한 곡선</strong>은 로드 밸런싱과 시퀀스 재정렬이 학습에 영향을 주지 않음을 검증</li> <li> <strong>이 결과는 실용적 채택을 가능하게 함</strong> - 수렴 검증 없이는 누구도 프로덕션에서 USP를 신뢰하지 않을 것</li> </ul> <h2 id="내-전체-평가-이-논문이-실제로-달성한-것">내 전체 평가: 이 논문이 실제로 달성한 것</h2> <h3 id="전략적-돌파구">전략적 돌파구</h3> <p>이 논문은 단순히 또 다른 최적화를 제안하는 것이 아니라 근본적인 시스템 문제를 해결합니다. 이 분야는 두 가지 경쟁하는 접근법(Ulysses vs Ring)을 가지고 있었고, 자연스러운 경향은 편을 선택하는 것이었습니다. 저자들의 이들을 결합하는 통찰은 연구자들이 데이터와 모델 병렬성 중 하나를 선택하는 대신 결합할 수 있다는 것을 깨달았던 획기적인 순간과 유사합니다.</p> <h3 id="실제-영향">실제 영향</h3> <p><strong>USP 이전</strong>: 긴 맥락 모델 훈련은 각 하드웨어 설정에 대해 올바른 병렬화 전략을 선택하는 전문 지식이 필요했습니다. 팀들은 구성을 튜닝하는 데 몇 주를 보냈습니다.</p> <p><strong>USP 이후</strong>: 자동으로 적응하는 하나의 통합 접근법. 이는 분산 시스템 전문 지식이 없는 팀들을 위해 긴 맥락 훈련을 민주화합니다.</p> <h3 id="기술적-우아함">기술적 우아함</h3> <p>로드 밸런싱 솔루션은 특히 우아합니다 - 인과 어텐션 작업 부하를 완벽하게 균형 맞추는 간단한 재정렬입니다. 이는 기본 수학적 구조에 대한 깊은 이해를 보여줍니다.</p> <h3 id="한계와-미래-연구">한계와 미래 연구</h3> <ol> <li> <strong>여전히 고급 하드웨어 필요</strong> - USP는 값비싼 GPU 클러스터의 필요성을 제거하지 않음</li> <li> <strong>통신 오버헤드 여전히 존재</strong> - 짧은 시퀀스에 대해 데이터 병렬화보다 여전히 높음</li> <li> <strong>메모리 효율성 격차</strong> - TP-sp는 메모리 중요 시나리오에서 장점을 유지</li> </ol> <h3 id="더-넓은-의미">더 넓은 의미</h3> <p>이 연구는 시퀀스 병렬화가 실험적 기술에서 프로덕션 준비 기술로 성숙했음을 나타냅니다. 208K 토큰에서 47% MFU는 단순한 벤치마크가 아니라 긴 맥락 AI가 이제 규모에서 실용적이라는 증명입니다.</p> <p><strong>내 예측</strong>: USP는 혼합 정밀도 훈련이 보편적으로 채택된 것처럼 긴 맥락 훈련의 표준 접근법이 될 것입니다. 자동 하드웨어 적응이 채택의 주요 장벽을 제거합니다.</p> <hr> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/fa3/">Flash Attention 3</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/fa2/">Flash Attention 2</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/fa/">Flash Attention</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/sp/">Reducing Activation Recomputation in Large Transformer Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/deepspeed_ulysses/">DeepSpeed Ulysses</a> </li> <div id="disqus_thread" style="max-width: 930px; margin: 0 auto;"> <script type="text/javascript">
    var disqus_shortname  = 'sungyubkim';
    var disqus_identifier = '/blog/usp';
    var disqus_title      = "Unified Sequence Parallelism";
    (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by Disqus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2026 Sung-Yub Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: January 29, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?v=c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>